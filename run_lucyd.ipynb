{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Outdated models '''\n",
    "# MODEL_NAME='lucyd-edof.pth'\n",
    "# MODEL_NAME='lucyd-edof-11.pth'\n",
    "\n",
    "''' New/relevant models '''\n",
    "# MODEL_NAME='lucyd-small-phantoms.pth' # original model trained on small phantoms\n",
    "#MODEL_NAME='lucyd-psf-sim-2.pth' # improved EDOF blur simlation (3d projections + microscopy PSF simulation)\n",
    "MODEL_NAME='lucyd-edof-plankton_231204.pth' # improved EDOF blur simlation (slightly less patchy results, trained with finer structures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lucyd import LUCYD, device\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import time \n",
    "import os\n",
    "\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "torch.cuda.set_per_process_memory_fraction(0.9, 0)\n",
    "#os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:512\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 8452\n"
     ]
    }
   ],
   "source": [
    "RESIZE=False\n",
    "RESIZE_RESOLUTION=(2560,2560) # will be ignored if RESIZE=False\n",
    "BG_CORR = True\n",
    "\n",
    "model = LUCYD(num_res=1).to(device)\n",
    "model.load_state_dict(torch.load('models/'+MODEL_NAME))\n",
    "model.eval()\n",
    "print('number of parameters: {}'.format(sum(p.numel() for p in model.parameters())))\n",
    "\n",
    "path = '/mnt/m181 PISCO1/M181-175-1_CTD-050_00deg00S-019deg00W_20220509-0543/PNG/'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Background correction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if BG_CORR:\n",
    "    files = os.listdir(path)\n",
    "    imgs = [cv.imread(os.path.join(path, file), cv.IMREAD_GRAYSCALE) for file in files]\n",
    "    bg = np.max(imgs, axis=0)\n",
    "    corrected = cv.absdiff(imgs[0], bg)\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "####Dataset \n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.nn.functional import pad\n",
    "import os\n",
    "from PIL import Image\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class UnlabelledImageDataset(Dataset):\n",
    "    def __init__(self, img_dir, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.img_names = sorted(os.listdir(img_dir))\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_names)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_names[idx])\n",
    "        image = Image.open(img_path).convert('L')\n",
    "        name = self.img_names[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, name  # Return a dummy label\n",
    "\n",
    "def collate_fn(batch):\n",
    "    # Find the max height and width in this batch\n",
    "    max_height = max(img.shape[1] for img, _ in batch)\n",
    "    max_width = max(img.shape[2] for img, _ in batch)\n",
    "\n",
    "    # Ensure max_height and max_width are even numbers\n",
    "    max_height += max_height % 2\n",
    "    max_width += max_width % 2\n",
    "\n",
    "    # Add padding to images in this batch and collate them into a single tensor\n",
    "    batch = [F.pad(img, (0, max_width - img.shape[2], 0, max_height - img.shape[1]), mode='constant', value=0) for img, _ in batch]\n",
    "    return torch.stack(batch), _ \n",
    "\n",
    "transform = transforms.Compose([\n",
    "        #transforms.Resize((2560,2560)),\n",
    "        #transforms.RandomCrop((512,512)),\n",
    "        #transforms.Resize((5120,5120)),\n",
    "        #transforms.RandomResizedCrop(224),\n",
    "        #transforms.RandomHorizontalFlip(),\n",
    "        #transforms.RandomRotation(degrees=(0, 180)),\n",
    "        #transforms.Grayscale(),\n",
    "        transforms.ToTensor(),\n",
    "        #transforms.Normalize([0.5,], [0.5,])\n",
    "    ])\n",
    "\n",
    "# Load the unseen dataset\n",
    "dataset = UnlabelledImageDataset('/home/plankton/Data/M181_test_set2/results', transform=transform)\n",
    "\n",
    "# Create a data loader\n",
    "#images = DataLoader(dataset, batch_size=1, collate_fn=collate_fn)\n",
    "images = DataLoader(dataset, batch_size=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119296\n",
      "2097152\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.memory_allocated())\n",
    "torch.cuda.empty_cache()\n",
    "print(torch.cuda.memory_reserved())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('inverted_0.png', 'inverted_1.png', 'inverted_10.png', 'inverted_11.png', 'inverted_12.png', 'inverted_13.png', 'inverted_14.png')\n",
      "Time to load image: 0.037109375 seconds\n",
      "Time to deconvolve: 1.0152018070220947 seconds\n",
      "Time to cpu x image: 0.028794050216674805 seconds\n",
      "Time to save image: 0.00475311279296875 seconds\n",
      "('inverted_15.png', 'inverted_16.png', 'inverted_17.png', 'inverted_18.png', 'inverted_19.png', 'inverted_2.png', 'inverted_20.png')\n",
      "Time to load image: 0.03096628189086914 seconds\n",
      "Time to deconvolve: 1.013456106185913 seconds\n",
      "Time to cpu x image: 0.1009521484375 seconds\n",
      "Time to save image: 0.013643264770507812 seconds\n",
      "('inverted_21.png', 'inverted_22.png', 'inverted_23.png', 'inverted_24.png', 'inverted_25.png', 'inverted_26.png', 'inverted_27.png')\n",
      "Time to load image: 0.030823707580566406 seconds\n",
      "Time to deconvolve: 1.0142197608947754 seconds\n",
      "Time to cpu x image: 0.10175919532775879 seconds\n",
      "Time to save image: 0.01735210418701172 seconds\n",
      "('inverted_28.png', 'inverted_29.png', 'inverted_3.png', 'inverted_30.png', 'inverted_31.png', 'inverted_32.png', 'inverted_33.png')\n",
      "Time to load image: 0.030961036682128906 seconds\n",
      "Time to deconvolve: 1.0121064186096191 seconds\n",
      "Time to cpu x image: 0.1015932559967041 seconds\n",
      "Time to save image: 0.01449894905090332 seconds\n",
      "('inverted_34.png', 'inverted_35.png', 'inverted_36.png', 'inverted_37.png', 'inverted_38.png', 'inverted_39.png', 'inverted_4.png')\n",
      "Time to load image: 0.030869722366333008 seconds\n",
      "Time to deconvolve: 1.0143179893493652 seconds\n",
      "Time to cpu x image: 0.10251927375793457 seconds\n",
      "Time to save image: 0.014291048049926758 seconds\n",
      "('inverted_40.png', 'inverted_41.png', 'inverted_42.png', 'inverted_43.png', 'inverted_44.png', 'inverted_45.png', 'inverted_46.png')\n",
      "Time to load image: 0.030895233154296875 seconds\n",
      "Time to deconvolve: 1.016252040863037 seconds\n",
      "Time to cpu x image: 0.028906583786010742 seconds\n",
      "Time to save image: 0.0047605037689208984 seconds\n",
      "('inverted_47.png', 'inverted_48.png', 'inverted_49.png', 'inverted_5.png', 'inverted_50.png', 'inverted_6.png', 'inverted_7.png')\n",
      "Time to load image: 0.030796289443969727 seconds\n",
      "Time to deconvolve: 1.0170810222625732 seconds\n",
      "Time to cpu x image: 0.028934478759765625 seconds\n",
      "Time to save image: 0.004703044891357422 seconds\n",
      "('inverted_8.png', 'inverted_9.png')\n",
      "Time to load image: 0.009019613265991211 seconds\n",
      "Time to deconvolve: 0.33365774154663086 seconds\n",
      "Time to cpu x image: 0.00829625129699707 seconds\n",
      "Time to save image: 0.010215997695922852 seconds\n"
     ]
    }
   ],
   "source": [
    "################\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "# NAME OF THE IMAGE YOU WANT TO DECONVOLVE\n",
    "#path = '/mnt/m181 PISCO1/M181-175-1_CTD-050_00deg00S-019deg00W_20220509-0543/PNG/'\n",
    "index = 0\n",
    "with torch.no_grad():\n",
    "    for image, name in iter(images):\n",
    "        start_time = time.time()\n",
    "        print(name)\n",
    "\n",
    "        #filename = os.path.join(path,file)\n",
    "        #result_fn = os.path.join('/home/plankton/Results/M181/Deconv/M181-175-1_CTD-050_00deg00S-019deg00W_20220509-0543',file)\n",
    "        result_fn = os.path.join('/home/plankton/Data/M181_test_set2/deconv_test', str(name)+'.png')\n",
    "        index += 1 \n",
    "\n",
    "        ################\n",
    "\n",
    "            #if RESIZE:\n",
    "            #    x = np.array(Image.open(filename).convert('L').resize(RESIZE_RESOLUTION))\n",
    "            #else:\n",
    "            #    x = np.array(Image.open(filename).convert('L'))\n",
    "        x = image\n",
    "        \n",
    "\n",
    "            #if x.shape[0] % 2 != 0: x = x[1:]\n",
    "            #if x.shape[1] % 2 != 0: x = x[:,1:]\n",
    "            # x = (x - np.min(x))/(np.max(x) - np.min(x))\n",
    "        \n",
    "\n",
    "        x_torch = x.to(device)\n",
    "        #print(torch.cuda.memory_allocated())\n",
    "        #print(torch.cuda.memory_reserved())\n",
    "        #torch.cuda.synchronize()        \n",
    "            #x_torch = x_torch.unsqueeze(0).unsqueeze(0)\n",
    "        print('Time to load image: {} seconds'.format(time.time() - start_time))\n",
    "        start_time = time.time()\n",
    "        y_hat, y_k, update = model(x_torch.float())\n",
    "        torch.cuda.synchronize()\n",
    "        print('Time to deconvolve: {} seconds'.format(time.time() - start_time))\n",
    "        start_time = time.time()\n",
    "            # plt.figure(figsize=(20,20))\n",
    "            # plt.subplot(1,2,1)\n",
    "        #y = x_torch.detach().cpu().numpy()[0,0]\n",
    "        #print('Time to detach y image: {} seconds'.format(time.time() - start_time))\n",
    "            # plt.imshow(y, cmap='gray')\n",
    "            # plt.title('Input')\n",
    "            # plt.subplot(1,2,2)\n",
    "        x = y_hat.detach().cpu().numpy()[0,0]\n",
    "        print('Time to cpu x image: {} seconds'.format(time.time() - start_time))\n",
    "        #x = x.numpy()[0,0]\n",
    "        #print('Time to numpy x image: {} seconds'.format(time.time() - start_time))\n",
    "        start_time = time.time()\n",
    "\n",
    "            # plt.imshow(x, cmap='gray', vmin=0)\n",
    "            # plt.title('Output')\n",
    "            # plt.show()\n",
    "        x = x*255*1.1\n",
    "        #cv.imwrite(result_fn, x)\n",
    "        del x\n",
    "\n",
    "        #Image.fromarray(x).convert('L').save(result_fn)\n",
    "        print('Time to save image: {} seconds'.format(time.time() - start_time))\n",
    "        #torch.cuda.empty_cache()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batchsize = 1\n",
    "allocated: 104976896\n",
    "reserved: 1155530752\n",
    "Time to load image: 0.003166675567626953 seconds\n",
    "Time to deconvolve: 0.19535279273986816 seconds\n",
    "Time to cpu x image: 0.0033130645751953125 seconds\n",
    "Time to save image: 0.024829626083374023 seconds\n",
    "\n",
    "Time per image ~0.2257 seconds\n",
    "\n",
    "## Batchsize = 4 \n",
    "allocated: 419549696\n",
    "reserved: 1260388352\n",
    "Time to load image: 0.017978191375732422 seconds\n",
    "Time to deconvolve: 0.5801444053649902 seconds\n",
    "Time to cpu x image: 0.016628026962280273 seconds\n",
    "Time to save image: 0.023236751556396484 seconds\n",
    "\n",
    "Time per image ~0.1615 seconds\n",
    "\n",
    "## Batchsize = 7\n",
    "734122496\n",
    "2311061504\n",
    "Time to load image: 0.031010866165161133 seconds\n",
    "Time to deconvolve: 1.0197343826293945 seconds\n",
    "Time to cpu x image: 0.10259056091308594 seconds\n",
    "Time to save image: 0.03341197967529297 seconds\n",
    "\n",
    "Time per image ~0.1571 seconds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "with torch.no_grad():\n",
    "    for image, _ in images:\n",
    "        start_time = time.time()\n",
    "\n",
    "        result_fn = os.path.join('/home/plankton/Results/M181/Deconv/batch_test',str(index)+'.png')\n",
    "        index += 1 \n",
    "\n",
    "        x = image\n",
    "\n",
    "        x_torch = x.to(device)\n",
    "        print('Time to load image: {} seconds'.format(time.time() - start_time))\n",
    "        start_time = time.time()\n",
    "        y_hat, y_k, update = model(x_torch.float())\n",
    "        print('Time to deconvolve: {} seconds'.format(time.time() - start_time))\n",
    "        start_time = time.time()\n",
    "            # plt.figure(figsize=(20,20))\n",
    "            # plt.subplot(1,2,1)\n",
    "        #y = x_torch.detach().cpu().numpy()[0,0]\n",
    "        #print('Time to detach y image: {} seconds'.format(time.time() - start_time))\n",
    "            # plt.imshow(y, cmap='gray')\n",
    "            # plt.title('Input')\n",
    "            # plt.subplot(1,2,2)\n",
    "        x = y_hat.detach().cpu().numpy()[0,0]\n",
    "        #print('Time to detach x image: {} seconds'.format(time.time() - start_time))\n",
    "            # plt.imshow(x, cmap='gray', vmin=0)\n",
    "            # plt.title('Output')\n",
    "            # plt.show()\n",
    "        x = x*255\n",
    "        cv.imwrite(result_fn, x)\n",
    "\n",
    "        #Image.fromarray(x).convert('L').save(result_fn)\n",
    "        print('Time to save image: {} seconds'.format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unprocessed directory found!\n",
      "remaining images: 20522\n",
      "Start segmenting\n",
      "Mask radius is: 1302\n",
      "10% done\n",
      "30% done\n",
      "40% done\n",
      "50% done\n",
      "70% done\n",
      "80% done\n",
      "100% done\n",
      "Total time: 1610.5983849840704, Avg time per img: 0.07848155077400207\n"
     ]
    }
   ],
   "source": [
    "#!cd /home/plankton/PISCO_Software/MaxSegmenter\n",
    "from MaxSegmenterModule import run_segmenter\n",
    "\n",
    "run_segmenter(\n",
    "        #source_folder=\"C:/Users/timka/Documents/Arbeit/PeruTest\",\n",
    "        source_folder=\"/home/plankton/Results/M181/Deconv/M181-175-1_CTD-050_00deg00S-019deg00W_20220509-0543/\",\n",
    "        save_crops=False,\n",
    "        save_marked_imgs=False,\n",
    "        save_bg_corr_imgs=True,\n",
    "        min_area_to_segment=1000,\n",
    "        min_area_to_save=1000,\n",
    "        save_path=\"/home/plankton/Results/M181/Deconv/M181-175-1_CTD-050_00deg00S-019deg00W_20220509-0543/bg_corr/\",\n",
    "        #save_path=\"C:/Users/timka/Documents/Arbeit/Results\",\n",
    "        equalize_hist=True,\n",
    "        resize=True,\n",
    "        clear_save_path=True,\n",
    "        bg_size=5,\n",
    "        max_threads=10,\n",
    "        n_sigma=2, #2 for M181 images, 1.5 for Cusco Peru\n",
    "        n_cores=8,\n",
    "        mask_imgs=True,\n",
    "        mask_radius_offset=200,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/plankton/PISCO_Software/MaxSegmenter\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/plankton/PISCO_Software/MaxSegmenter'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%cd /home/plankton/PISCO_Software/MaxSegmenter\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unprocessed directory found!\n",
      "remaining images: 20521\n",
      "Start segmenting\n",
      "Mask radius is: 2820\n",
      "No progress detected, terminating status update...\n",
      "Total time: 2011.0037388849305, Avg time per img: 0.09799735582500514\n"
     ]
    }
   ],
   "source": [
    "run_segmenter(\n",
    "        #source_folder=\"C:/Users/timka/Documents/Arbeit/PeruTest\",\n",
    "        source_folder=\"/mnt/m181 PISCO1/M181-175-1_CTD-050_00deg00S-019deg00W_20220509-0543/PNG/\",\n",
    "        save_crops=False,\n",
    "        save_marked_imgs=False,\n",
    "        save_bg_corr_imgs=True,\n",
    "        min_area_to_segment=1000,\n",
    "        min_area_to_save=1000,\n",
    "        save_path=\"/home/plankton/Results/M181/M181-175-1_CTD-050_00deg00S-019deg00W_20220509-0543/\",\n",
    "        #save_path=\"C:/Users/timka/Documents/Arbeit/Results\",\n",
    "        equalize_hist=True,\n",
    "        resize=True,\n",
    "        clear_save_path=True,\n",
    "        bg_size=5,\n",
    "        max_threads=10,\n",
    "        n_sigma=2, #2 for M181 images, 1.5 for Cusco Peru\n",
    "        n_cores=8,\n",
    "        mask_imgs=True,\n",
    "        mask_radius_offset=200,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 400.00 MiB (GPU 0; 7.78 GiB total capacity; 6.36 GiB already allocated; 707.19 MiB free; 7.01 GiB allowed; 6.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m/home/plankton/underwater-lucyd/run_lucyd.ipynb Cell 15\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.136.67.158/home/plankton/underwater-lucyd/run_lucyd.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m x_torch \u001b[39m=\u001b[39m x_torch\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.136.67.158/home/plankton/underwater-lucyd/run_lucyd.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=29'>30</a>\u001b[0m start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B10.136.67.158/home/plankton/underwater-lucyd/run_lucyd.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=30'>31</a>\u001b[0m y_hat, y_k, update \u001b[39m=\u001b[39m model(x_torch\u001b[39m.\u001b[39;49mfloat())\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.136.67.158/home/plankton/underwater-lucyd/run_lucyd.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mTime to deconvolve: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m seconds\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time))\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.136.67.158/home/plankton/underwater-lucyd/run_lucyd.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39m# plt.figure(figsize=(20,20))\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.136.67.158/home/plankton/underwater-lucyd/run_lucyd.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=34'>35</a>\u001b[0m \u001b[39m# plt.subplot(1,2,1)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.136.67.158/home/plankton/underwater-lucyd/run_lucyd.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=35'>36</a>\u001b[0m \u001b[39m#y = x_torch.detach().cpu().numpy()[0,0]\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.136.67.158/home/plankton/underwater-lucyd/run_lucyd.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=36'>37</a>\u001b[0m \u001b[39m# plt.imshow(y, cmap='gray')\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.136.67.158/home/plankton/underwater-lucyd/run_lucyd.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=37'>38</a>\u001b[0m \u001b[39m# plt.title('Input')\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.136.67.158/home/plankton/underwater-lucyd/run_lucyd.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=38'>39</a>\u001b[0m \u001b[39m# plt.subplot(1,2,2)\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/underwater-lucyd/lucyd.py:146\u001b[0m, in \u001b[0;36mLUCYD.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m    145\u001b[0m     a1 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcorrection_branch[\u001b[39m0\u001b[39m](x)\n\u001b[0;32m--> 146\u001b[0m     a2 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mEncoder[\u001b[39m0\u001b[39;49m](a1)\n\u001b[1;32m    147\u001b[0m     a3 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcorrection_branch[\u001b[39m1\u001b[39m](a2)\n\u001b[1;32m    149\u001b[0m     b1 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mupdate_branch[\u001b[39m0\u001b[39m](x)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/underwater-lucyd/lucyd.py:52\u001b[0m, in \u001b[0;36mEBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m---> 52\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlayers(x)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    203\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 204\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    205\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/underwater-lucyd/lucyd.py:41\u001b[0m, in \u001b[0;36mResBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m---> 41\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmain(x) \u001b[39m+\u001b[39m x\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    203\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 204\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    205\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/underwater-lucyd/lucyd.py:29\u001b[0m, in \u001b[0;36mBasicConv.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m---> 29\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmain(x)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    203\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 204\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    205\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/batchnorm.py:171\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    164\u001b[0m     bn_training \u001b[39m=\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunning_mean \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m) \u001b[39mand\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunning_var \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    166\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[39mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[1;32m    168\u001b[0m \u001b[39mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \u001b[39mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 171\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mbatch_norm(\n\u001b[1;32m    172\u001b[0m     \u001b[39minput\u001b[39;49m,\n\u001b[1;32m    173\u001b[0m     \u001b[39m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrunning_mean\n\u001b[1;32m    175\u001b[0m     \u001b[39mif\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining \u001b[39mor\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrack_running_stats\n\u001b[1;32m    176\u001b[0m     \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    177\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrunning_var \u001b[39mif\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining \u001b[39mor\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrack_running_stats \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    178\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight,\n\u001b[1;32m    179\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias,\n\u001b[1;32m    180\u001b[0m     bn_training,\n\u001b[1;32m    181\u001b[0m     exponential_average_factor,\n\u001b[1;32m    182\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49meps,\n\u001b[1;32m    183\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/functional.py:2450\u001b[0m, in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2447\u001b[0m \u001b[39mif\u001b[39;00m training:\n\u001b[1;32m   2448\u001b[0m     _verify_batch_size(\u001b[39minput\u001b[39m\u001b[39m.\u001b[39msize())\n\u001b[0;32m-> 2450\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mbatch_norm(\n\u001b[1;32m   2451\u001b[0m     \u001b[39minput\u001b[39;49m, weight, bias, running_mean, running_var, training, momentum, eps, torch\u001b[39m.\u001b[39;49mbackends\u001b[39m.\u001b[39;49mcudnn\u001b[39m.\u001b[39;49menabled\n\u001b[1;32m   2452\u001b[0m )\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 400.00 MiB (GPU 0; 7.78 GiB total capacity; 6.36 GiB already allocated; 707.19 MiB free; 7.01 GiB allowed; 6.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "################\n",
    "from pynvml import *\n",
    "nvmlInit()\n",
    "h = nvmlDeviceGetHandleByIndex(0)\n",
    "\n",
    "# NAME OF THE IMAGE YOU WANT TO DECONVOLVE\n",
    "path = '/home/plankton/Data/M181_test_set2'\n",
    "for file in os.listdir(path):\n",
    "\n",
    "    filename = os.path.join(path,file)\n",
    "    result_fn = os.path.join('/home/plankton/Results/M181/Deconv/M181-175-1_CTD-050_00deg00S-019deg00W_20220509-0543_bg_corr',file)\n",
    "    ################\n",
    "\n",
    "    with torch.no_grad():\n",
    "        if RESIZE:\n",
    "            x = np.array(Image.open(filename).convert('L').resize(RESIZE_RESOLUTION))\n",
    "        else:\n",
    "            x = np.array(Image.open(filename).convert('L'))\n",
    "\n",
    "        if x.shape[0] % 2 != 0: x = x[1:]\n",
    "        if x.shape[1] % 2 != 0: x = x[:,1:]\n",
    "        # x = (x - np.min(x))/(np.max(x) - np.min(x))\n",
    "        x = x/255\n",
    "\n",
    "        x_torch = torch.from_numpy(x).to(device)\n",
    "        #y_torch = torch.from_numpy(x).to(device)\n",
    "\n",
    "        x_torch = x_torch.unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "        start_time = time.time()\n",
    "        y_hat, y_k, update = model(x_torch.float())\n",
    "        print('Time to deconvolve: {} seconds'.format(time.time() - start_time))\n",
    "\n",
    "        # plt.figure(figsize=(20,20))\n",
    "        # plt.subplot(1,2,1)\n",
    "        #y = x_torch.detach().cpu().numpy()[0,0]\n",
    "        # plt.imshow(y, cmap='gray')\n",
    "        # plt.title('Input')\n",
    "        # plt.subplot(1,2,2)\n",
    "        x = y_hat.detach().cpu().numpy()[0,0]\n",
    "        # # plt.imshow(x, cmap='gray', vmin=0)\n",
    "        # # plt.title('Output')\n",
    "        # # plt.show()\n",
    "        info = nvmlDeviceGetMemoryInfo(h)\n",
    "\n",
    "\n",
    "        print(f'total   : {info.total * 1e-6} MB')\n",
    "        print(f'free   : {info.free* 1e-6} MB')\n",
    "        print(f'used   :  {info.used* 1e-6} MB')\n",
    "        print(torch.cuda.memory_allocated(0) * 1e-6)\n",
    "        print(torch.cuda.memory_reserved(0) * 1e-6)\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        Image.fromarray(x*255.).convert('L').save(result_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total   : 8589.934592 MB\n",
      "free   : 741.5398399999999 MB\n",
      "used   :  7848.394751999999 MB\n",
      "6824.89856\n",
      "7132.413952\n"
     ]
    }
   ],
   "source": [
    "info = nvmlDeviceGetMemoryInfo(h)\n",
    "\n",
    "\n",
    "print(f'total   : {info.total * 1e-6} MB')\n",
    "print(f'free   : {info.free* 1e-6} MB')\n",
    "print(f'used   :  {info.used* 1e-6} MB')\n",
    "print(torch.cuda.memory_allocated(0) * 1e-6)\n",
    "print(torch.cuda.memory_reserved(0) * 1e-6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "97cc609b13305c559618ec78a438abc56230b9381f827f22d070313b9a1f3777"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
